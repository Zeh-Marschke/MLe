{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kreuzvalidierung\n",
    "Die Aufteilung in Trainingsmenge und Testmenge bedeutet, dass nur ein Teil der Lernmenge für das Training zur Verfügung steht.\n",
    "Insbesondere bei kleinen Datenmengen ist das kritisch, da die Aufteilung einen starken Einfluss auf das Ergebnis hat.\n",
    "Wenige Elemente können einen großen Einfluss auf das Ergebnis haben.\n",
    "Dies wurde in ML03b-Entscheidungsbaum bereits demonstriert. \n",
    "\n",
    "Die **Kreuzvalidierung** (*cross validation*, **CV**) kann diese Situation verbessern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 $k$-Teilmengen Kreuzvalidierung\n",
    "Bei einer einzelnen Aufteilung der Daten kann das Ergebnis unter- oder überbewertet werden.\n",
    "Also eine Leistung, beispielsweise die Kennzahl für die Genauigkeit, liefern große Unterschied \n",
    "im Vergleich zur Kennzahl bei einer anderen Aufteilung.\n",
    "Ziel ist es, eine Abschätzung für die typische, durchschnittliche Leistung zu erzielen.\n",
    "Auch eine Abschätzung zur Unsicherheit der Leistung, soll erzielt werden.\n",
    "\n",
    "Bei einer Aufteilung wird ein Teil der Lernmenge nicht in das Training mit einbezogen.\n",
    "Das ist schlecht, wenn es nur wenige Daten gibt oder es zu aufwändig ist, mehr Daten zu erhalten.\n",
    "Bei der Kreuzvalidierung werden verschiedene Aufteilungen vorgenommen, \n",
    "so dass die Aufteilung in Trainingsmenge / Testmenge sich verändert. \n",
    "Mit jeder Aufteilung wird das Training, die Vorhersage und die Bewertung durchgeführt.\n",
    "Die übergeordnete Bewertung ist dann der Mittelwert (oder der Median) der einzelnen Bewertungen.\n",
    "Als Streuparameter kann die Standardabweichung (oder die Interquartialsdifferenz) gewählt werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wie wird die Kreuzvalidierung durchgeführt?\n",
    "Die Lernmenge wird in $k$ (möglichst gleich große) Teilmengen unterteilt.\n",
    "Es werden dann $k$ Iterationen durchgeführt.\n",
    "In jeder Iteration ist jeweils eine der $k$ Teilmengen die Testmenge,\n",
    "die anderen Teilmengen bilden zusammen die Trainingsmenge.\n",
    "Somit besteht die Trainingsmenge aus den $(k-1)$ Teilmengen, welche nicht die Traininhgsmenge ist.\n",
    "Damit ist jede Teilmenge und jedes einzelne Element genau einmal in der Testmenge und $(k-1)$-Mal in der Trainingsmenge.\n",
    "Da die Teilmengen in etwa gleich groß sind, haben alle Ergebnisse das gleiche Gewicht.\n",
    "\n",
    "Im nachfolgenden Bild ist die Aufteilung in fünf Teilmengen dargestellt. \n",
    "In jedem der fünf Durchläufe ist eine der fünf Teilmengen die Testmenge, die anderen die Trainingsmenge.\n",
    "\n",
    "<img src=\"ExampleCrossValidation.png\" style=\"zoom:60%;\" /> \n",
    "\n",
    "**Wichtig**: Insbesondere bei schlecht ausgewogenen Lernmengen ist es wichtig, dass die einzelnen Teilmengen in etwa\n",
    "dieselbe Verteilung der Klassen haben, wie die Gesamtmenge. \n",
    "Dies kann zum einen erzielt werden, wenn die Teilmengen per Zufall zusammengesetzt werden.\n",
    "Zum anderen kann die Lernmenge am Beginn gut durchmischt (*shuffle*)werden. Dann kann die Lernmenge segmentiert werden.\n",
    "Es kann ach so durchgeführt werden, dass sichergestelt wird, dass alle Teilmengen die gleiche Verteilung haben.\n",
    "Dieses Vorgehen wird **Schichtenbildung** (*stratification*) genannt.\n",
    "\n",
    "Es werden dann insgesamt $k$ Vorhersagen durchgeführt und $k$ Kennzahlen ermittelt.\n",
    "Welche ist die beste oder die richtige Kennzahl? Keine davon!\n",
    "Aus den $k$ Kennzahlen wird ein Schätzer für die erwartete Kennzahl und die Unsicherheit \n",
    "für die Generalisierung berechnet.\n",
    "Das entgültige Modell wird aus der gesamten Lernmenge gebildet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wie viele Teilmengen sollen gebildet werden?\n",
    "Wenn ein großer Wert von $k$ gewählt wird, dann gibt es Vor- und Nachteile:\n",
    "- Nachteil: der Zeitaufwand steigt linear mit der Anzahl von $k$, denn es werden $k$ Durchläufe abgewickelt.\n",
    "- Vorteil: Die Abschätzung der Parameter wird zuverlässiger, da die statistische Unsicherheit sinkt.\n",
    "- Vorteil: Der Generalisierungsfehler entspricht in etwa dem, was im CV-Prozess berechnet wird.\n",
    "\n",
    "Daher ist die Wahl des geeigneten $k$ eine Abwägung zwischen Verbesserung der Genauigkeit durch mehr Wiederholungen\n",
    "und der dabei benötigten Rechenzeit.\n",
    "Typische Werte sind 5 - 10. Es sollte nicht unter 3 gehen.\n",
    "\n",
    "**Spezialfall** \n",
    "Bei der **Leave-One-Out Kreuzvalidierung** (*Leave-One-Out Cross Validation*, **LOO-CV**) werden so viele Iterationen durchgeführt,\n",
    "wie es Elemente in der Lernmenge gibt. Somit ist bei jedem Durchlauf nur ein einizges Element in der Testmenge.\n",
    "Bei der **Leave-p-Out Kreuzvalidierung** (*Leave-p-Out Cross Validation*, **LpO-CV**) werden $p$ Elemente in die Testmenge gestellt,\n",
    "die anderen Element sind in der Trainingsmenge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Beispiel: Habitable Planenten - Entscheidungsbaum\n",
    "Dieses Vorgehen wird nun an der Lernmenge der habitablen Planten durchgeführt. \n",
    "Es sind die Daten, die bereits in ML03b-Bewertung verwendet wurden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of               exoplanets in the list :  5350\n",
      "number of not habitable exoplanets in the list :  5280\n",
      "number of     habitable exoplanets in the list :    70\n"
     ]
    }
   ],
   "source": [
    "# --- read the data - complete\n",
    "### Die Pfadangabe kann abhängig vom Betriebssystem Probleme machen\n",
    "### bei Windows okay, bei Linux ? bei MacOS? --> Testen mit Linux\n",
    "filename = \"data/HabitablePlanets_work.csv\"\n",
    "hwc = np.genfromtxt (filename, delimiter=',', \\\n",
    "                     usecols = (1, 2, 3, 4), skip_header = 1)\n",
    "print (f\"number of               exoplanets in the list : {hwc.shape [0]:5d}\")\n",
    "\n",
    "# -- split in features and label\n",
    "hwc_features = hwc [:,0:3]\n",
    "hwc_label = hwc [:,3]\n",
    "unique, counts = np.unique (hwc_label, return_counts = True)\n",
    "print (f\"number of not habitable exoplanets in the list : {counts [0]:5d}\")\n",
    "print (f\"number of     habitable exoplanets in the list : {counts [1]:5d}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es werden $k = 5$ Teilmengen gebildet. Es werden nun drei verschiedene Varianten demonstriert.\n",
    "Die Aufteilung wird mit hilfe von `sklearn` realisiert. \n",
    "Es werden auch die Verteilungen von nicht habitablen und habitablen Planeten in den jeweiligen Teilmengen dargestellt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- imports\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "\n",
    "# --- set parameters for all variants!\n",
    "k_splits = 5\n",
    "random_state = 2024\n",
    "\n",
    "# --- routine to show distribution of data\n",
    "def print_distribution (train, test, label):\n",
    "    n_train_hab = np.sum (label [train])\n",
    "    n_train_non = train.size - n_train_hab\n",
    "    n_test_hab = np.sum (label [test])\n",
    "    n_test_non = test.size - n_test_hab\n",
    "    print (f\" train: [{n_train_non:5.0f} - {n_train_hab:3.0f}]\" + \\\n",
    "           f\"   test: [{n_test_non:5.0f} - {n_test_hab:3.0f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante 1: Standardversion, ohne mischen der Daten.\n",
    "Die Reihenfolge der Daten bleibt erhalten.\n",
    "Die Daten sind nicht so ganz gleichmäßig verteilt, aber nicht so schlimm.\n",
    "\n",
    "Im Exremfall, wenn alle habitablen Planeten hintereinander aufgeführt sind, dann sind alle in einer Teilmenge. \n",
    "In den anderen Teilmengen dann keine habitablen Planeten.\n",
    "Dies führt zu schlechten Ergebnissen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train: [ 4221 -  59]   test: [ 1059 -  11]\n",
      " train: [ 4225 -  55]   test: [ 1055 -  15]\n",
      " train: [ 4229 -  51]   test: [ 1051 -  19]\n",
      " train: [ 4227 -  53]   test: [ 1053 -  17]\n",
      " train: [ 4218 -  62]   test: [ 1062 -   8]\n"
     ]
    }
   ],
   "source": [
    "cv1 = KFold (n_splits = k_splits)\n",
    "\n",
    "# -- show the distribution\n",
    "for train, test in cv1.split (hwc_features, hwc_label): \n",
    "    print_distribution (train, test, hwc_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante 2: In dieser Variante, die von Viviana Acquaviva [Acq2023] empfohlen wird, werden die Daten vorher durchmischt.\n",
    "Hier, bei diesem Beispiel, zeigen sich nur geringe Unterschiede zur Variante 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train: [ 4229 -  51]   test: [ 1051 -  19]\n",
      " train: [ 4219 -  61]   test: [ 1061 -   9]\n",
      " train: [ 4224 -  56]   test: [ 1056 -  14]\n",
      " train: [ 4219 -  61]   test: [ 1061 -   9]\n",
      " train: [ 4229 -  51]   test: [ 1051 -  19]\n"
     ]
    }
   ],
   "source": [
    "cv2 = KFold (shuffle = True, n_splits = k_splits, random_state = random_state)\n",
    "\n",
    "# -- show the distribution\n",
    "for train, test in cv2.split (hwc_features, hwc_label): \n",
    "    print_distribution (train, test, hwc_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variante 3: In dieser Variante wird eine Schichtenbildung (*stratification*) durchgeführt. \n",
    "Die Menge sind nahezu gleich verteilt und entsprechen der Verteilung in der Gesamtmenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train: [ 4224 -  56]   test: [ 1056 -  14]\n",
      " train: [ 4224 -  56]   test: [ 1056 -  14]\n",
      " train: [ 4224 -  56]   test: [ 1056 -  14]\n",
      " train: [ 4224 -  56]   test: [ 1056 -  14]\n",
      " train: [ 4224 -  56]   test: [ 1056 -  14]\n"
     ]
    }
   ],
   "source": [
    "cv3 = StratifiedKFold(shuffle = True, n_splits = k_splits, \\\n",
    "                      random_state = random_state)\n",
    "\n",
    "# -- show the distribution\n",
    "for train, test in cv3.split (hwc_features, hwc_label): \n",
    "    print_distribution (train, test, hwc_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird das Modell Entscheidungsbaum mit den obigen drei verschiedenen Varianten bearbeitet. \n",
    "Für jeden der fünf Durchläufe wird jeweils die Genauigkeit berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "DT_model = DecisionTreeClassifier()\n",
    "scores1 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv1, \\\n",
    "                          scoring = 'accuracy')\n",
    "scores2 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv2, \\\n",
    "                          scoring = 'accuracy')\n",
    "scores3 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv3, \\\n",
    "                          scoring = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Ausgabe, sind die Trainingszeiten und Vorhersagezeiten je Durchlauf gespeichert.\n",
    "Ebenso ist die Kennzahl, hier die Genauigkeit der fünf Durchlüufe, gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00702095, 0.00699282, 0.0060308 , 0.00797915, 0.00599432]),\n",
       " 'score_time': array([0.        , 0.00095057, 0.00098348, 0.00099921, 0.00099659]),\n",
       " 'test_score': array([0.98878505, 0.98691589, 0.98130841, 0.98037383, 0.98598131])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit können die Mittelwerte und die Standardabweichungen für die Genauigkeit der drei verschiedenen Varianten berechnet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variant 1: 0.985 +/- 0.003\n",
      "variant 2: 0.987 +/- 0.003\n",
      "variant 3: 0.985 +/- 0.003\n"
     ]
    }
   ],
   "source": [
    "print (f\"variant 1: {scores1 ['test_score'].mean ():5.3f} \" \\\n",
    "       + f\"+/- {scores1 ['test_score'].std () :5.3f}\")\n",
    "print (f\"variant 2: {scores2 ['test_score'].mean ():5.3f} \" \\\n",
    "       + f\"+/- {scores2 ['test_score'].std () :5.3f}\")\n",
    "print (f\"variant 3: {scores3 ['test_score'].mean ():5.3f} \" \\\n",
    "       + f\"+/- {scores3 ['test_score'].std () :5.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Ergebnisse unterscheiden sich nicht wesentlich von der Genauigkeit beim faulen Modell. \n",
    "Es gibt keinen signifikanten Unterschied, da die Abweichungen kleiner als die Standardabweichungen sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt wird als Kennzahl der Trefferquote herangezogen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variant 1: 0.459 +/- 0.094\n",
      "variant 2: 0.513 +/- 0.098\n",
      "variant 3: 0.443 +/- 0.153\n"
     ]
    }
   ],
   "source": [
    "scores1 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv1, \\\n",
    "                          scoring = 'recall')\n",
    "scores2 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv2, \\\n",
    "                          scoring = 'recall')\n",
    "scores3 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv3, \\\n",
    "                          scoring = 'recall')\n",
    "\n",
    "print (f\"variant 1: {scores1 ['test_score'].mean ():5.3f} \" \\\n",
    "       + f\"+/- {scores1 ['test_score'].std () :5.3f}\")\n",
    "print (f\"variant 2: {scores2 ['test_score'].mean ():5.3f} \" \\\n",
    "       + f\"+/- {scores2 ['test_score'].std () :5.3f}\")\n",
    "print (f\"variant 3: {scores3 ['test_score'].mean ():5.3f} \" \\\n",
    "       + f\"+/- {scores3 ['test_score'].std () :5.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nun wird die Kennzahl für die jeweilige Trainingsmenge betrachtet.\n",
    "Ausgegeben wird die Trefferquote (nur der Mittelwert) auf der Testmenge und auf der Trainingsmenge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "variant 1: test 0.472   training 1.000\n",
      "variant 2: test 0.479   training 1.000\n",
      "variant 3: test 0.429   training 1.000\n"
     ]
    }
   ],
   "source": [
    "scores1 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv1, \\\n",
    "                          scoring = 'recall', return_train_score = True)\n",
    "scores2 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv2, \\\n",
    "                          scoring = 'recall', return_train_score = True)\n",
    "scores3 = cross_validate (DT_model, hwc_features, hwc_label, cv = cv3, \\\n",
    "                          scoring = 'recall', return_train_score = True)\n",
    "\n",
    "print (f\"variant 1: test {scores1 ['test_score'].mean ():5.3f}   \" \\\n",
    "       + f\"training {scores1 ['train_score'].mean () :5.3f}\")\n",
    "print (f\"variant 2: test {scores2 ['test_score'].mean ():5.3f}   \" \\\n",
    "       + f\"training {scores2 ['train_score'].mean () :5.3f}\")\n",
    "print (f\"variant 3: test {scores3 ['test_score'].mean ():5.3f}   \" \\\n",
    "       + f\"training {scores3 ['train_score'].mean () :5.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00701809, 0.00698304, 0.00595117, 0.00797606, 0.0059967 ]),\n",
       " 'score_time': array([0.00395298, 0.00196362, 0.00202847, 0.00199556, 0.00198174]),\n",
       " 'test_score': array([0.63636364, 0.33333333, 0.36842105, 0.64705882, 0.375     ]),\n",
       " 'train_score': array([1., 1., 1., 1., 1.])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenig überraschend ist die Trefferquote in der Trainingsmenge jeweils 100%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Damit sind zwar Kennzahlen ermittelt, aber keine Vorhersagen. \n",
    "Es gibt in jedem Durchlauf Vorhersagen. Diese können nun verbunden werden.\n",
    "Damit kann dann die Wahrheitsmatrix erstellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Confusion Matrix       |     predicted label     |\n",
      "                         | non hab    | hab        |\n",
      "-------------------------+------------+------------+\n",
      "              non hab    | TN=   5243 | FP=     37 |\n",
      "  true label  -----------+------------+------------+\n",
      "              hab        | FN=     36 | TP=     34 |\n",
      "-------------------------+------------+------------+\n",
      "\n",
      "    accuracy    = 0.9864\n",
      "    precision   = 0.4789\n",
      "    recall      = 0.4857\n",
      "    FP-rate     = 0.0070\n",
      "    TP-rate     = 0.4857\n",
      "    F1-score    = 0.4823\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from tools import show_confusion_matrix_extended\n",
    "\n",
    "# --- predict\n",
    "y2_pred = cross_val_predict (DT_model, hwc_features, hwc_label, cv = cv2)\n",
    "\n",
    "# --- display confusion matrix\n",
    "show_confusion_matrix_extended (hwc_label, y2_pred, labels = [\"non hab\", \"hab\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literatur\n",
    "- [Acq2023] Viviana Acquaviva; Machine Learning for Physics and Astronomy; Princeton University Press; 2023\n",
    "- [Van2024] Jake VanderPlas; Handbuch Data Science mit Python; O'Reilly; 2024; (Übersetzung der 2. Auflage von *Python Data Science Handbook*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
