{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Sprache der maschinellen Lernens\n",
    "\n",
    "### 1 Instanzen, Eigenschaften, Ergebnis und Modell\n",
    "\n",
    "Für das MLn werden Daten herangezogen und analysiert. Die Daten bestehen aus $N$ **Instanzen** (*instances*).\n",
    "Die Instanzen werden machmal auch kurz Beispiele (*sampes*,*examples*) oder in der Physik Beobachtungen (*observables*) genannt. \n",
    "Diese Instanzen bestehen aus $n$ bekannten **Eigenschaften** (*features*) auch die *Input*-Daten genannt. \n",
    "Diese Eigenschaften können numerische Werte sein, müssen es jedoch nicht. \n",
    "Für die weitere Verarbeitung ist es jedoch notwendig, wenn alle Daten numerisch sind. \n",
    "Hierzu kann eine einfache Abbildung von nicht-numerischen Werten auf numerische Werte durchgeführt werden. \n",
    "Darüber hinaus gibt es eine Eigenschaften, die aus den *Input*-Daten abgeleitet werden soll. \n",
    "Diese Daten heißen **Ergebnis** (*target*), die auch *Output*-Daten genannt werden.\n",
    "\n",
    "Damit sind die Input-Daten $X$ eine reelle $N \\times n$-Matrix, $X = (x_{i,j}) \\in \\mathbb{R}^{N \\times n}$.\n",
    "In jeder der $N$ Zeilen stehen die *features* der Instanzen. In jeder einzelnen der $n$ Spalten stehen die\n",
    "Daten für ein *feature*.\n",
    "Die Output-Daten bilden einen reellen Vektor der Länge $N$: $\\textbf{y} = (y_i)^T \\in \\mathbb{R}^{N}$. \n",
    "In ihm stehen die *target*s der einzelnen Instanzen.\n",
    "\n",
    "Bei klassischen Programmen wird eine Funktion geschrieben, welche die Eingabedaten in die Ausgabedaten transformiert. \n",
    "Hierzu muss die Funktion jedoch bekannt sein. Beim ML hingegebn ist die Funktion oder die Parameter der Funktion nicht bekannt. \n",
    "Es soll ein möglichst gutes **Maschinelles Lernen-Modell** (*maschine learning model*) erstellt - gelernt - werden, \n",
    "welches die *Output*-Daten aus den *Input*-Daten ermittelt. Dann kann auch für unbekannte Datensätze \n",
    "aus gegebenen Input-Daten die Output-Daten vorhergesagt werden.\n",
    "\n",
    "### 2 Lerndaten, Trainingsdaten, Testdaten\n",
    "\n",
    "Beim überwachten Lernen wird die Sammlung von Daten, die für das Lernen zur Verfügung stehen als **Lerndaten** (*learning set*) bezeichnet.\n",
    "Für diese Lerndaten sind die Input-Daten und die dazugehörigen Output-Daten bekannt.\n",
    "Diese Lerndaten werden in zwei Teile zerlegt:\n",
    "- Mit den **Trainingsdaten** (*training set*) wird ein Modell und die dazugehörigen Parameter berechnet, welche die\n",
    "Beziehung zwischen den Input-Daten und den Output-Daten beschreibt.\n",
    "- Mit den **Testdaten** (*test set*) wird das Modell und die bestimmten Parameter überprüft. Es wird somit geprüft,\n",
    "ob das Modell, das aus den Trainingsdaten bestimmt wird, die Testdaten gut beschreiben.\n",
    "\n",
    "Die $N$ Instanzen werden aufgeteilt in $N_{train}$ Trainingsdaten ($X_{train}$, $\\textbf{y}_{train}$) \n",
    "und $N_{test}$ Testdaten ($X_{test}$, $\\textbf{y}_{test}$).\n",
    "Dies ist ein zufälliger Prozess. Eine gebräuchliche Aufteilung ist 70% Trainingsdaten und 30% Testdaten.\n",
    "Diese Werte können jedoch variieren.\n",
    "\n",
    "Wichtig dabei ist die zufällige Auswahl der Trainingsdaten, damit die Trainingsdaten ein\n",
    "repräsentatives Bild der gesamten Daten abgeben!\n",
    "Nach Viviana Acquaviva [Acq2023] ist das überwachte Lernen nur so gut, wie die Daten, die in den Lerndaten enthalten sind\n",
    "(*a supervised learning method is only as good as its learning set*):\n",
    "- gibt es zu wenig Daten, dann kann das Modell den Zusammenhang zwischen Input und Output nicht richtig erlernen,\n",
    "- ist die Auswahl der Daten in den Lerndaten nicht repräsentativ für alle Daten, dann lernt das Modell einen falschen Zusammenhang.\n",
    "\n",
    "Daher ist es wichtig, die Daten zu verstehen. Dazu wird das Fachwissen benötigt, um die Daten richtig zu interpretieren. \n",
    "Viviana Acquaviva schreibt dazu: \n",
    "\n",
    "*Because [machine learning techniques] are driven by the data as opposed to relying on physical intuition,\n",
    "we are bound to make a fool of ourselves if we don't understand the data well.*\n",
    "\n",
    "### 3 Fehlerrate, Erfolgsrate\n",
    "Für die Überprüfung, ob das gewählte Modell eine gute Beschreibung der Beziehung zwischen Input-Daten und Output-Daten ist,\n",
    "wird die **Fehlerrate** (*rate of failure (error)*) beziehungsweise \n",
    "die **Erfolgsrate** (*rate of success (score)*) bestimmt. Dies wird sowohl bei den\n",
    "Trainingsdaten als auch bei den Testdaten durchgeführt. Damit werden\n",
    "- **Trainingsfehlerrate** (*training error*), **Trainingserfolgsrate** (*training score*) und\n",
    "- **Testsfehlerrate** (*test error*), **Testerfolgsrate** (*test score*)\n",
    "\n",
    "ermittelt. Wenn das Modell auf Daten angewendet werden, die nicht in den Lerndaten enthalten sind, \n",
    "dann werden ebenso Fehler und Erfolg gemessen. Dies wird dann **Generalisierungsfehler** (*gerneralization error*) \n",
    "beziehungsweise **Generalisierungerfolg** (*generalization score*) genannt.\n",
    "\n",
    "Durch den Vergleich von diesen Kennzahlen (später werden noch weitere Kennzahlen eingeführt) werden die Ergebnisse\n",
    "verschiedener Modelle und auch unterschiedlicher Parametrisierungen von Modellen verglichen, um damit abzuwägen,\n",
    "welche Modelle und welche Parameter für die Modelle geeignet sind.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Der generelle Ablauf\n",
    "\n",
    "Wie sieht der Ablauf beim Maschinellen Lernen aus. Viviana Acquviva beschreibt den Ablauf folgendermaßen (siehe [Acq2023]):\n",
    "\n",
    "#### Schritt 1: Aufbereitung der Daten\n",
    "\n",
    "**Datenaufbereitung** Die Daten, die verwendet werden müssen oftmals aufbereitet werden.\n",
    "Auch der Umgang mit fehlenden Daten muss geklärt werden. \n",
    "Die Daten werden dabei oftmals als ein *panda-Datenframe* bereitsgestellt.\n",
    "Hier wird jedoch das Werkzeug *panda* nicht genauer betrachtet. \n",
    "Die Daten werden als ein $numpy-array$ aufgebaut,\n",
    "wobei die Daten bereinigt sind.\n",
    "(Wenn die Daten als *panda-datenframe* kommen, \n",
    "dann werden sie für die weitere Bearbeitung meistens in ein *numpy-array* umgewandelt.)\n",
    "\n",
    "**Splitten** Die Daten werden aufgeteilt in Trainingsdaten und Testdaten.\n",
    "Damit stehen am Ende dieses Schritten die Trainingsdaten $X_{train}$, $\\textbf{y}_{train}$ \n",
    "und die Testdaten $X_{test}$, $\\textbf{y}_{test}$ zur Verfügung.\n",
    "\n",
    "#### Schritt 2: ML Algorithmus auswählen\n",
    "In diesem Schritt wird der Algorithmus gewählt, der für das Training angewendet werden soll. \n",
    "Dabei werden auch die Parameter für den Algorithmus festgelegt.\n",
    "\n",
    "Beispiel: Soll ein Polynom bestimmt werden, dann ist festzulegen, welchen Grad das Polynom haben soll.\n",
    "Der Grad des Polynoms ist dann ein *Hyperparameter*, die noch unbekannten Koeffizienten des Polynoms\n",
    "die *Parameter*, die bestimmt werden sollen.\n",
    "\n",
    "Es gibt sehr viele ML Algorithmen, die gewählt werden können. Es können hier nur einige wenige vorgestellt werden. \n",
    "Grundlegende Begriffe, wie Trainingsdaten, Testdaten, Fehlerrate, Erfolgsrate und weitere Begriffe,\n",
    "die im folgenden noch besprochen werden sind jedoch für alle gleich.\n",
    "\n",
    "#### Schritt 3: Modell mit Hilfe der Trainingsdaten bilden (*fit*)\n",
    "Der ausgewählte Algorithmus wird auf die Trainingsdtaen angewendet. Dies generiert dann ein vorläufige\n",
    "Beziehung zwischen den Input- und Outputdaten. Damit wird also der Zusammenhang, gemäß dem gewählten\n",
    "Algorithmus beschrieben. Dies ist in der Regeln ein sehr rechenintensiver Vorgang.\n",
    "\n",
    "#### Schritt 4: Modell auf die Testdaten anwenden (*predict*)\n",
    "Das vorhandene Modell, wird auf die Testdaten angewendet. Aus den Inputdaten der Testdaten werden Vorhersagen \n",
    "für die Output-Daten erstellt $\\hat{\\textbf{y}}_{test}$. Das sind die Vorhersagewerte auf Basis des ermittelten Modells.\n",
    "\n",
    "#### Schritt 5: Perfomance bestimmen\n",
    "Auf Basis eine vorab bestimmten Bewertungsmaßstabes (*evaluation metric*) wird die Perfomance des Modells\n",
    "auf die Daten ermittelt. Hierzu findet ein Vergleich der Vorhersagewerte $\\hat{\\textbf{y}}_{test}$ \n",
    "mit den echten Werten $\\textbf{y}_{test}$ statt.\n",
    "\n",
    "#### Schritt 6: Ergebnis analysieren\n",
    "Es kann sein, dass das erzielte Ergebnis gut ist - das ist jedoch in der Regel unwahrscheinlich.\n",
    "Oftmals muss man überlegen, was verbessert werden kann oder muss. \n",
    "Sollen die Hyperparameter für den Algorithmus anders gewählt werden, \n",
    "werden mehr Daten benötigt, \n",
    "was funktioniert nicht so gut, was muss besser gestaltet werden.\n",
    "\n",
    "Daraufhin kann der ML Algorithmus geändert oder verändert werden und das Ablauf wiederholt sich\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Literatur\n",
    "- [Acq2023] Viviana Acquaviva; Machine Learning for Physisics and Astronomy; Princeton University Press; 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
