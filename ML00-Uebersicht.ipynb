{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maschinelles Lernen - Überblick\n",
    "Übersicht über zu erstellende Bausteien (Jupyter Notebooks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bausteine 01: Einführung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN01a - Einführung\n",
    "- Klärung was ML was und was damit gemacht werden kann\n",
    "  (recognize,predict, Group together, simplify)\n",
    "- TODO: Grenzen der \"klassischen\" Bearbeitung . Wo macht es Sinn ML einzusetzen,\n",
    "  an welchen Stellen eventuell nicht. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN01b - Die Sprache des ML\n",
    "- Definition wichtiger Begriffe \n",
    "  (instances, features, labels, machine learning model)\n",
    "- Verfahren im ML\n",
    "  (supervized learning, unsupervized learning,reinforcement learning)\n",
    "- Supervized learning\n",
    "  (training set, test set, error (rate of failure), score (rate of success)\n",
    "   Training error / score, test error / score, generalization error / score,\n",
    "    rpresentative laerning set)\n",
    "- Classification vs. Regression\n",
    "- Unsupervized learning (Clustering, dimensionality reduction) \n",
    "- ML Modell - grundlegende Ablauf\n",
    "  (1) Daten aufbereiten; (2) Daten aufteilen in Trainings- und Testdaten\n",
    "  (3) ML Methode und seine Parameter auswählen\n",
    "  (4) Fit durchführen: Die ML Methode auf die Trainingsdaten anwenden\n",
    "  (5) Vorhersagen: Modell auf die Testdaten anwenden\n",
    "  (6) Berechnung der Performace durch Anwendung einer geeigneten Bewertungsmethode\n",
    "  (7) Ergebnis betrachten, Schwachstellen erkennen, Verbesserungen durchführen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN01c - Maschinelles Lernen versus Deduction\n",
    "- Beispiel Lineare Regression mit Daten y = m * x + b + Nor(0, u)\n",
    "- Wann ML einsetzen, wann geeigneter direkte Ableitung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bausteine 02: Binäre Klassifikation (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN02b - Binäre Klassifikation - Decision Tree\n",
    "- Daten (habitable Planten) aufbereiten\n",
    "- Split durchführen\n",
    "  (Wie berechnet man den besten Split)\n",
    "- Wie tief soll gesplittet werden?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN02c - Binäre Klassifikation - kNN (k-Nearest Neigbour)\n",
    "- Daten darstellen (nicht normalisiert / normalisiert)\n",
    "- Mittelwert vs. Median"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bausteine 03: Binäre Klassifikation (2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN03a - Daten aufbereiten\n",
    "- Komplette Dasten der Exoplanten mit Hilfe von pandas aufberieten\n",
    "- Ziel ist eine CSV-Datei, die direkt mit numpy eingelesen werden kann\n",
    "- pandas nur andeuten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN03b - Binäre Klassifizierung - Bewertung und Diagnose\n",
    "- Bewertung bei binärer Klassifikation\n",
    "  (true positive (TP), true negative (TN), false positive (FP), false negative (FN),\n",
    "  accuracy, precosion, recall, confusion matrix)\n",
    "- TODO: Receiver operating curve (ROC), Area under the curve (AUC)\n",
    "- Bewertungsmethode auswählen\n",
    "- Bewertungen am Beispiel von Decision Tree\n",
    "- Durchführen mit kNN als Aufgabe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN03c - Cross Validation - derzeit in Vorbereitung\n",
    "- cross validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN03d - Diagnose - derzeit in Vorbereitung\n",
    "- Overfitting and underfitting\n",
    "- high bias, high variance\n",
    "- learning curve\n",
    "- hyperparameter Tuning\n",
    "- feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JN03e - Multi Klassifikation - etwas nach hinten geschoben"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bausteine 04: Optimierungen - in Planung\n",
    "- LHC-Daten Partikel-Kollision ?\n",
    "- Support Vector Machine (trennbare Eigenschaften; Schlupfvariablen, Kernel-Methoden); \n",
    "- Datenvorbereiten; \n",
    "- Diagnose und Optimierung\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bausteine 05: Regression - in Vorbereitung\n",
    "- Evaluation\n",
    "- (multi-)lineare Regression (least sqaures, mse\n",
    "- Loss-Funktion\n",
    "- Gradientenabstieg\n",
    "- Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bausteine 06: Ensemble-Methoden - in Planung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bausteine 08: Einführung in Neuronale Netzwerke - in Planung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literatur\n",
    "- [Acq2023] Viviana Acquaviva; Machine Learning for Physics and Astronomy; Princeton University Press; 2023\n",
    "- [Fro2021] Jörg Frochte; Maschinelles Lernen - Grundlagen und Algorithmen in Python; Hanser; 2021\n",
    "- [Ngu2021] Chi Nhan Nguyen, Oliver Zeigermann; Machine Learning kurz & gut; O'Reilly; 2021\n",
    "- [Ras2019] Sebastian Raschka, Vahid Mirjalili; Python Machine Learning; Packt; 2019\n",
    "- [Van2024] Jake VanderPlas; Handbuch Data Science mit Python; O'Reilly; 2024; (Übersetzung der 2. Auflage von *Python Data Science Handbook*)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
